[general]

BlockArchitecture = MixedBlockArchitecture
ClassCount = 10

Verbose = True
Multithreaded = False
Distributed = False
DatasetModule = Demos.Datasets.MNIST
GenBlockArchitecture = Demos.gen_classification_ba
# Set the number of threads to be used, 0 does not set a limit, -1 sets the number to the number presented
# by the CPU to the OS
ThreadCount = 1
# Please note that if us ing the GPU you should run the program using a single thread, multi-threaded training usually
# leads to GPU memory issues as GPU memory management struggles to allocate memory between threads.
GPU = True
Log = True
TraceMemoryUse = True

[evolution]

VerboseMutation = True
MutationProbability = 0.8
CrossoverProbability = 0.1
# Number of times an architecture is attempted to be mutated should it mutate into an invalid architecture
MutationAttempts = 10
RetrainEveryGeneration = False
UseReinforcementLearningMutation = True
# Alpha value used for mutation function reinforcement learning
Alpha = 0.2

# Mutation can happen in one of two ways, either there is an EQUAL probability for every block in the hierarchy or
# via the given (or default) self-mutation PROBABILITY value, eg. 0.5 self-mutation means that each block has a 50% chance to
# mutate itself. As such the value can be used to shift the focus on mutating to either the top or bottom of the
# hierarchy, eg. 0.5 means the second block layer has a 50% chance while the third has a 25% chance, similarly a 0.9
# value gives the second block layer a 9% chance while the third layer has a 81% chance, assuming a hierarchy of depth
# 3.
# To have ALL mutation methods in the entire block architecture as equally probable, one can also specity ALL.
;MutationMethod = EQUALLY
MutationMethod = PROBABILITY
;MutationMethod = ALL
SelfMutationProbability = 0.3

# Certain search processes use a mutation probability that causes mutation to happen at increasingly deeper levels during
# the search progress, eg. simulated annealing. Thus, one can set the change that should be applied to the mutation
# probability with each generation, either positive (shifting mutation lower) or negative (shifting mutation higher).
VariableMutationGenerationalChange = 0.00

PopulationSize = 100
GenerationCount = 10


[output]

FigureTitle = Goal Attainment
SaveIndividuals = True
OutputPrefix = MIXED_probability_no_mlonmcu

# How often should the generations be visualized
GenerationGap = 1

# Saving individuals can be done, EVERY generation or at a specified INTERVAL, the final generation is always saved
GenerationSave = EVERY
GenerationSaveInterval = 1

[goals]

# number of goals or the length of goal vector
GoalsNumber = 2
# names of the goals tha appear in log file (every 2 goals needs to be separated by a comma and space ", ")
GoalsNames = Parameters, Accuracy

### Goal vector
GoalVector = (804554, 98)
### Normalization vector
NormalizationVector = (10000, 1)

[mlonmcu]

UseMLonMCU = False
metrics = Cycles, Total ROM, Total RAM
platform = mlif
backend = tvmaotplus
target = etiss_pulpino
frontend = tflite
# Choose the postprocesses to apply (choices: filter_cols, rename_cols, features2cols, config2cols, passcfg2cols, 
# visualize, bytes2kb, artifact2cols, analyse_instructions, compare_rows)
postprocess = None
feature = None
configs = None
parllel = 1
progress = False
verbose = False

[filter]

FilterFunction = MinMaxArray
FilterFunctionModule = TensorNAS.FilterFunctions.MinMax

# The multi-objective optimization requires that every objective has a weight that signifies if it should be
# minimized or maximized, as such the weights can be set to be all 'maximized', all 'minimize' or manually set,
# eg. -1, 1, -1

Weights = (1, -1)

[tensorflow]

# -1 meaning to take the absolute length of the input training & test data
TrainingSampleSize = -1
TestSampleSize = -1
ValidationSplit = 0.1
Optimizer = adam
Loss = sparse_categorical_crossentropy
Metrics = accuracy
EarlyStopper = True
Patience = 4
StopperMonitor = val_accuracy
StopperMinDelta = 0.005
StopperMode = max

# 6GB GPU
BatchSize = 512
# For 24GB GPU
# BatchSize = 10000
TestBatchSize = 32
Epochs = 10
QuantizationAware = False